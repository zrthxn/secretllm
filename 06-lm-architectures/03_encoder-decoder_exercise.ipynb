{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Transformer (T5-like Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement an encoder-decoder transformer model similar to T5. The model is designed for sequence-to-sequence tasks like translation or summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device (\"mps\" if you're using an M series mac):\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample vocabulary and data\n",
    "vocab = ['[PAD]', '[BOS]', '[EOS]', 'i', 'like', 'eating', 'apples', 'bananas', 'fruits']\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Tokens\n",
    "There are some different tokens you might stumble across when dealing with inputs in NLP. \n",
    "- The [PAD] Token acts as a padding if a sentence does not have the desired fixed length. \n",
    "- The [BOS] Token indicates the Beginning of the Sentence. \n",
    "- The [EOS] Token indicates the End of the Sentence. \n",
    "- The [CLS] Token represents Sentence Level Classification. \n",
    "- The [SEP] Token represents Separation of Sentences (used by BERT). \n",
    "- The [UNK] Token represents OOB-Tokens, meaning unknown Tokens that are not included in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input-output pairs (e.g., paraphrasing)\n",
    "input_sentences = [\n",
    "    ['[BOS]', 'i', 'like', 'eating', 'apples', '[EOS]'],\n",
    "    ['[BOS]', 'i', 'like', 'eating', 'bananas', '[EOS]']\n",
    "]\n",
    "output_sentences = [\n",
    "    ['[BOS]', 'i', 'like', 'fruits', '[EOS]'],\n",
    "    ['[BOS]', 'i', 'like', 'fruits', '[EOS]']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def prepare_data(sentences):\n",
    "    inputs = []\n",
    "    for sent in sentences:\n",
    "        input_ids = [word_to_idx[word] for word in sent]\n",
    "        inputs.append(input_ids)\n",
    "    return torch.tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "encoder_inputs = prepare_data(input_sentences).to(device)\n",
    "decoder_inputs = prepare_data([['[BOS]'] + sent[1:] for sent in output_sentences]).to(device)\n",
    "decoder_targets = prepare_data([sent[1:] + ['[PAD]'] for sent in output_sentences]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding (same as before)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, model_dimension, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # TODO: Implement positional encoding\n",
    "        # Create a positional encoding matrix with shape (max_len, d_model)\n",
    "        # Use torch.arange and torch.exp to calculate the positional encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer (same as before)\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, model_dimension, num_attention_heads, dim_feedforward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # TODO: Implement encoder layer components\n",
    "        # Multi-head self-attention\n",
    "        \n",
    "        # Feedforward network (linear, dropout, linear)\n",
    "        \n",
    "        # Layer normalization, twice\n",
    "        \n",
    "        # Dropout layers, twice\n",
    "        \n",
    "\n",
    "    def forward(self, input_tensor, src_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        # Self-attention, dropout and norm\n",
    "        \n",
    "        # Feedforward network\n",
    "        # linear, relu, dropout, linear\n",
    "        \n",
    "        # dropout and norm\n",
    "        \n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, model_dimension, num_attention_heads, dim_feedforward, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # TODO: Implement decoder layer components\n",
    "        # Multi-head self-attention\n",
    "        \n",
    "        # Feedforward network (linear, dropout, linear)\n",
    "        \n",
    "        # Layer normalization, thrice\n",
    "        \n",
    "        # Dropout layers\n",
    "        \n",
    "\n",
    "    def forward(self, target, memory, target_mask=None, memory_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        # Self-attention\n",
    "        \n",
    "        # Multi-head attention with encoder output\n",
    "        \n",
    "        # Feedforward network\n",
    "        \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder (same as before)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_attention_heads, vocab_size, dim_feedforward, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        # TODO: Implement encoder components\n",
    "        # Embedding and Positional Encoding\n",
    "        \n",
    "        # Create multiple encoder layers\n",
    "        \n",
    "\n",
    "    def forward(self, input_sequence, src_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        # Embedding Positional Encoding and Permutation\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        \n",
    "        return input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # TODO: Implement decoder components\n",
    "        # Embedding and Positional Encoding\n",
    "        \n",
    "        # Create multiple decoder layers\n",
    "        \n",
    "\n",
    "    def forward(self, target, memory, tgt_mask=None, memory_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        # Embedding Positional Encoding and Permutation\n",
    "        \n",
    "        # Pass through decoder layers\n",
    "        \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq Model\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, nhead, vocab_size, dim_feedforward, dropout=0.1):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        # TODO: Implement Seq2Seq model components\n",
    "        # Encoder and Decoder, as well as output layer\n",
    "        \n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        # Pass through encoder, then decoder, then output layer\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_layers = 2\n",
    "model_dimension = 64\n",
    "num_attention_heads = 4\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = Seq2SeqModel(num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_idx['[PAD]'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks (not used in this simple example)\n",
    "source_attention_mask = None\n",
    "target_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3137\n",
      "Epoch 20/100, Loss: 0.0894\n",
      "Epoch 30/100, Loss: 0.0484\n",
      "Epoch 40/100, Loss: 0.0372\n",
      "Epoch 50/100, Loss: 0.0279\n",
      "Epoch 60/100, Loss: 0.0227\n",
      "Epoch 70/100, Loss: 0.0197\n",
      "Epoch 80/100, Loss: 0.0160\n",
      "Epoch 90/100, Loss: 0.0147\n",
      "Epoch 100/100, Loss: 0.0135\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # TODO: Forward pass\n",
    "    # Pass encoder inputs, decoder inputs, and masks to the model\n",
    "    \n",
    "    # Reshape outputs and targets\n",
    "    outputs = outputs.view(-1, vocab_size)\n",
    "    targets = decoder_targets.view(-1)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: Generate output sequence\n",
    "def generate_sequence(model, input_sentence, max_length=10):\n",
    "    model.eval()\n",
    "    input_ids = [word_to_idx.get(word, word_to_idx['[PAD]']) for word in input_sentence]\n",
    "    source_tensor = torch.tensor([input_ids]).to(device)\n",
    "    memory = model.encoder(source_tensor)\n",
    "    target_tokens = [word_to_idx['[BOS]']]\n",
    "    for _ in range(max_length):\n",
    "        target = torch.tensor([target_tokens]).to(device)\n",
    "        output = model.decoder(target, memory)\n",
    "        output = model.output_layer(output.permute(1, 0, 2))\n",
    "        next_token = output.argmax(-1)[:, -1].item()\n",
    "        target_tokens.append(next_token)\n",
    "        if next_token == word_to_idx['[EOS]']:\n",
    "            break\n",
    "    output_sentence = [idx_to_word[idx] for idx in target_tokens]\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: ['[BOS]', 'i', 'like', 'eating', 'apples', '[EOS]']\n",
      "Generated Sentence: ['[BOS]', 'i', 'like', 'fruits', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_sentence = ['[BOS]', 'i', 'like', 'eating', 'apples', '[EOS]']\n",
    "generated_sentence = generate_sequence(model, test_sentence)\n",
    "print(\"Input Sentence:\", test_sentence)\n",
    "print(\"Generated Sentence:\", generated_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
