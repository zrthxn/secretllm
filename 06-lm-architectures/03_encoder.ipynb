{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Only Transformer (BERT-like Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement an encoder-only transformer model similar to BERT. The model is designed for Masked Language Modeling (MLM), where certain tokens in the input are masked, and the model learns to predict the masked tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4y/1jmthrw909g7xn3g2lf71r280000gn/T/ipykernel_26564/2778190235.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/arthurnurnberg/Library/Mobile Documents/com~apple~CloudDocs/Arbeit/TUD Tutor LLMs/06_lm_architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # mainly for ReLU\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device (\"mps\" if you're using an M series mac):\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Tokens\n",
    "There are some different tokens you might stumble across when dealing with inputs in NLP. \n",
    "- The [PAD] Token acts as a padding if a sentence does not have the desired fixed length. \n",
    "- The [BOS] Token indicates the Beginning of the Sentence. \n",
    "- The [EOS] Token indicates the End of the Sentence. \n",
    "- The [CLS] Token represents Sentence Level Classification. \n",
    "- The [SEP] Token represents Separation of Sentences (used by BERT). \n",
    "- The [UNK] Token represents OOB-Tokens, meaning unknown Tokens that are not included in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample vocabulary and data\n",
    "vocab = ['[PAD]', '[MASK]', '[CLS]', '[SEP]', 'i', 'like', 'eating', 'apples', 'and', 'bananas', 'really']\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Sample sentences for showcasing possible input\n",
    "sentences = [\n",
    "    ['[CLS]', 'i', 'like', 'eating', 'apples', '[SEP]'],\n",
    "    ['[CLS]', 'i', 'like', 'eating', 'bananas', '[SEP]'],\n",
    "    ['[CLS]', 'i', 'really', 'like', 'apples', '[SEP]']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(sentences, mask_prob=0.15):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for sent in sentences:\n",
    "        input_ids = [word_to_idx[word] for word in sent]\n",
    "        label_ids = input_ids.copy()\n",
    "        for i in range(1, len(sent) - 1):  # Exclude [CLS] and [SEP] tokens\n",
    "            if torch.rand(1).item() < mask_prob:\n",
    "                input_ids[i] = word_to_idx['[MASK]']\n",
    "        inputs.append(input_ids)\n",
    "        labels.append(label_ids)\n",
    "    return torch.tensor(inputs), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "inputs, labels = mask_tokens(sentences)\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, model_dimension, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # TODO: Implement positional encoding\n",
    "        positional_encoding = torch.zeros(max_len, model_dimension)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        frequency_divisor = torch.exp(torch.arange(0, model_dimension, 2).float() * (-np.log(10000.0) / model_dimension))\n",
    "        positional_encoding[:, 0::2] = torch.sin(position * frequency_divisor)\n",
    "        positional_encoding[:, 1::2] = torch.cos(position * frequency_divisor)\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', positional_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, model_dimension, num_attention_heads, dim_feedforward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # TODO: Implement encoder layer components\n",
    "        self.self_attention_layer = nn.MultiheadAttention(model_dimension, num_attention_heads, dropout=dropout)\n",
    "        # Feedforward network\n",
    "        self.linear1 = nn.Linear(model_dimension, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, model_dimension)\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(model_dimension)\n",
    "        self.norm2 = nn.LayerNorm(model_dimension)\n",
    "        # Dropout layers\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_tensor, source_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        feedforward_output = self.self_attention_layer(input_tensor, input_tensor, input_tensor, attn_mask=source_mask)[0]\n",
    "        input_tensor = input_tensor + self.dropout1(feedforward_output)\n",
    "        input_tensor = self.norm1(input_tensor)\n",
    "        # Feedforward network\n",
    "        feedforward_output = self.linear2(self.dropout(F.relu(self.linear1(input_tensor))))\n",
    "        input_tensor = input_tensor + self.dropout2(feedforward_output)\n",
    "        input_tensor = self.norm2(input_tensor)\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        # TODO: Implement encoder components\n",
    "        self.model_dimension = model_dimension\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dimension)\n",
    "        self.positional_encoder = PositionalEncoding(model_dimension)\n",
    "        # Create multiple encoder layers\n",
    "        encoder_layer = EncoderLayer(model_dimension, num_attention_heads, dim_feedforward, dropout)\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(model_dimension)\n",
    "\n",
    "    def forward(self, input_sequence, src_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        input_sequence = self.embedding(input_sequence) * np.sqrt(self.model_dimension)\n",
    "        input_sequence = self.positional_encoder(input_sequence)\n",
    "        input_sequence = input_sequence.permute(1, 0, 2)  # Transformer expects (sequence length, batch size, embedding size)\n",
    "        for layer in self.layers:\n",
    "            input_sequence = layer(input_sequence, src_mask)\n",
    "        input_sequence = self.norm(input_sequence)\n",
    "        return input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Model\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout=0.1):\n",
    "        super(BERTModel, self).__init__()\n",
    "        # TODO: Implement BERT model components\n",
    "        self.encoder = Encoder(num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout)\n",
    "        self.output_layer = nn.Linear(model_dimension, vocab_size)\n",
    "\n",
    "    def forward(self, input_sequence, input_sequence_mask=None):\n",
    "        # TODO: Implement forward pass\n",
    "        encoder_output = self.encoder(input_sequence, input_sequence_mask)\n",
    "        encoder_output = encoder_output.permute(1, 0, 2)  # Back to (batch size, sequence length, embedding size)\n",
    "        logits = self.output_layer(encoder_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_layers = 2\n",
    "model_dimension = 64\n",
    "num_attention_heads = 4\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = BERTModel(num_layers, model_dimension, num_attention_heads, vocab_size, dim_feedforward, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_idx['[PAD]'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.9608\n",
      "Epoch 20/50, Loss: 0.2906\n",
      "Epoch 30/50, Loss: 0.1274\n",
      "Epoch 40/50, Loss: 0.0760\n",
      "Epoch 50/50, Loss: 0.0506\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # TODO: Forward pass\n",
    "    outputs = model(inputs)\n",
    "    # Reshape outputs and labels\n",
    "    outputs = outputs.view(-1, vocab_size)\n",
    "    labels_flat = labels.view(-1)\n",
    "    loss = criterion(outputs, labels_flat)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: Predict masked tokens\n",
    "def predict_masked_tokens(model, input_sentence):\n",
    "    model.eval()\n",
    "    input_ids = [word_to_idx.get(word, word_to_idx['[PAD]']) for word in input_sentence]\n",
    "    input_tensor = torch.tensor([input_ids]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "    predicted_sentence = [idx_to_word[idx.item()] for idx in predictions[0]]\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: ['[CLS]', 'i', 'like', '[MASK]', '[MASK]', '[SEP]']\n",
      "Predicted Sentence: ['[CLS]', 'i', 'like', 'eating', 'eating', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_sentence = ['[CLS]', 'i', 'like', '[MASK]', '[MASK]', '[SEP]']\n",
    "predicted_sentence = predict_masked_tokens(model, test_sentence)\n",
    "print(\"Input Sentence:\", test_sentence)\n",
    "print(\"Predicted Sentence:\", predicted_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
