{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9a683-e430-46bc-9685-6adbe565448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import logging\n",
    "import itertools\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "# from torchvision import transforms\n",
    "# import torchvision.transforms.functional as TF\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import CLIPTextModel\n",
    "\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    ControlNetModel,\n",
    "    DDPMScheduler,\n",
    "    StableDiffusionControlNetPipeline,\n",
    "    UNet2DConditionModel)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "MODELS = Path(\"/projects/p_scads_llm_secrets/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9392fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer, scheduler and models\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELS / \"stable-diffusion-v1-5\", subfolder=\"tokenizer\")\n",
    "\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(MODELS / \"stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
    "\n",
    "text_encoder = CLIPTextModel.from_pretrained(MODELS / \"stable-diffusion-v1-5\", subfolder=\"text_encoder\")\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(MODELS / \"stable-diffusion-v1-5\", subfolder=\"vae\")\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(MODELS / \"stable-diffusion-v1-5\", subfolder=\"unet\")\n",
    "\n",
    "# Load controlnet\n",
    "controlnet = ControlNetModel.from_pretrained(MODELS / \"sd-controlnet-scribble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline with all components\n",
    "pipeline = StableDiffusionControlNetPipeline(\n",
    "    unet=unet,\n",
    "    vae=vae,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    scheduler=noise_scheduler,\n",
    "    controlnet=controlnet,\n",
    "    feature_extractor=None,\n",
    "    # Safety checker is how the model knows not to generate anything objectionable\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca6bcd",
   "metadata": {},
   "source": [
    "## Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox\n",
    "from ipycanvas import RoughCanvas, hold_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1349fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c47364c7b84a1980dd09d6023472b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RoughCanvas(height=512, sync_image_data=True, width=512),))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CANVAS_WIDTH = 512\n",
    "CANVAS_HEIGHT = 512\n",
    "\n",
    "canvas = RoughCanvas(width=CANVAS_WIDTH, height=CANVAS_HEIGHT, sync_image_data=True)\n",
    "drawing = False\n",
    "position = None\n",
    "\n",
    "def on_mouse_down(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "    drawing = True\n",
    "    position = (x, y)\n",
    "\n",
    "def on_mouse_move(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "    if not drawing:\n",
    "        return\n",
    "    with hold_canvas():\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "        position = (x, y)\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "    drawing = False\n",
    "    with hold_canvas():\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "HBox((canvas,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = canvas.get_image_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017ca1c",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38303fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\n",
    "    \"Drawing of something\",\n",
    "    sketch, \n",
    "    num_inference_steps=50, \n",
    "    height=512,\n",
    "    width=512,\n",
    "    guidance_scale=7.5\n",
    ").images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
