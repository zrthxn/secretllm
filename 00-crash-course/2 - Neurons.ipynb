{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now look at an implementation of a neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from graphviz import Digraph\n",
    "import math\n",
    "\n",
    "# Reusing the draw function from the previous notebook\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in the graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v._prev:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir':'LR'}) # Left to right graph\n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    dot.node(name=uid, label= \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')  # added grad to the node \n",
    "\n",
    "    if n._op: # will work for non empty _op for every node, e.g for e, d, L \n",
    "      dot.node(name=uid + n._op, label= n._op ) # creating a node for the operation\n",
    "      dot.edge(uid + n._op, uid) # connecting the operation (oval) node to the Value [rectangle] node\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2._op) # connecting the parent to the child with the operation, if there is any\n",
    "\n",
    "  return dot\n",
    "\n",
    "\n",
    "# Reusing the value class from the previous notebook, plus some extra methods and checks\n",
    "class Value:\n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = 0\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "    self._backward = lambda: None\n",
    "    self._len_expression_graph = 1\n",
    "  def __repr__(self):\n",
    "    return f\"Value (data = {self.data})\"\n",
    "  \n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self, other), '+')\n",
    "    def _backward():\n",
    "      self.grad += out.grad\n",
    "      other.grad += out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "  \n",
    "  def __radd__(self, other):\n",
    "    return self.__add__(other)\n",
    "  \n",
    "  def __neg__(self):\n",
    "    return self * -1\n",
    "  \n",
    "  def __sub__(self, other):\n",
    "    return self + (-other)\n",
    "  \n",
    "  def __rsub__(self, other):\n",
    "    return Value(other) - self\n",
    "\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self, other), '*')\n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "  def __rmul__(self, other):\n",
    "    return self.__mul__(other)  \n",
    "\n",
    "  def __truediv__(self, other): # self / other\n",
    "    return self * other ** -1 # (self) * (other^-1) precendence is set automatically\n",
    "  \n",
    "  def __rtruediv__(self, other): # other / self\n",
    "    return Value(other) * self ** -1\n",
    "\n",
    "  def __pow__(self,other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float for now\"\n",
    "    out = Value(self.data ** other, (self,), f'**{other}')\n",
    "    def _backward():\n",
    "      self.grad += other * self.data ** (other - 1) * out.grad\n",
    "      # other.grad += self.data ** other * math.log(self.data) * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "  def exp(self):\n",
    "      x = self.data\n",
    "      out = Value(math.exp(x), (self,), 'exp')\n",
    "      def _backward():\n",
    "        self.grad += out.data * out.grad\n",
    "      out._backward = _backward\n",
    "      return out\n",
    "\n",
    "  def tanh(self):\n",
    "    out = Value(math.tanh(self.data), (self,), 'tanh')\n",
    "    def _backward(): \n",
    "      self.grad += (1 - out.data**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "  \n",
    "  def backward(self):\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "    self.grad = 1\n",
    "    for node in reversed(topo):\n",
    "      node._backward()\n",
    "    self._len_expression_graph = len(topo)\n",
    "\n",
    "  def reset_grad(self):\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        v.grad = 0.0\n",
    "    build_topo(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again let's look at the diagram of a mathematical neuron object\n",
    "\n",
    "![neuron](./img/neuron.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The task of a single neuron is to do multiply and accumulate. In other words, it's doing a vector dot product between two vectors. One is the input $x$ and the other is the weights $w$. Then it passes that through an activation function $(\\sigma)$ to introduce non linearity.\n",
    "\n",
    "In other words, if we consider a neuron to be a function $f(x)$, $$f(x) = \\sigma(<w|x> + b)= \\sigma(\\sum_{i}^{n}w_i\\cdot x_i + b)$$\n",
    "\n",
    "\n",
    "Let's now look at it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value (data = -0.9999851078292815)"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Neuron:\n",
    "\n",
    "  def __init__ (self, nin): # nin is the number of inputs to the neuron\n",
    "    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)] # weights\n",
    "    self.b = Value(random.uniform(-1,1))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # w*x + b\n",
    "    act = sum([wi*xi for wi, xi in zip(self.w, x)], self.b)\n",
    "    out = act.tanh()\n",
    "    return out\n",
    "  \n",
    "x = [2.0, 5.0]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great. Now we want to build a neural network. \n",
    "\n",
    "A neural network is an example of an $n-\\text{partite}$ graph. Neurons are connected to each other in layers. And no two neurons from the same layer have a connection between them. Generally all the neurons from one level are connected to all the other neurons in the next level (though in practice we sometimes delete edges between neurons)\n",
    "\n",
    "\n",
    "![neural-network](./img/neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now introduce a layer class which implements the collection on neurons abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value (data = -0.9759714399535733),\n",
       " Value (data = 0.9812483691737701),\n",
       " Value (data = -0.9847353887038769)]"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Layer:\n",
    "\n",
    "  def __init__(self, nin, nout):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nout)] # number of neurons in the layer\n",
    "\n",
    "  def __call__(self, x):\n",
    "    outs = [n(x) for n in self.neurons]\n",
    "    return outs[0] if len(outs) == 1 else outs\n",
    "  \n",
    "x = [3.0, 5.0]\n",
    "l = Layer(2, 3)\n",
    "l(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's build a multi layer perceptron using the classes defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  def __init__(self, nin, nouts): # list of number of neurons in each layer\n",
    "    sz = [nin] + nouts\n",
    "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(sz)-1)] # creating the layers\n",
    "\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./img/neural_net2.jpeg\" width=\"500\"/>\n",
    "</div>\n",
    "<h3>Language models are statistical models which predict what text to generate based on a given seed text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value (data = 0.39842930102413593)"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Implementing the above diagram in code\n",
    "x = [3.0, 5.0, -2.0] # 3 inputs\n",
    "n = MLP(3, [4, 4, 1]) # 3 inputs, two hidden layers with 4 neurons each, 1 output\n",
    "n(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The diagram of the expression graph of this whole MLP would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_dot(n(x)) # uncomment to see the diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A real example of this architure in work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value (data = 0.4176343392415774),\n",
       " Value (data = -0.8502455552187628),\n",
       " Value (data = 0.47749095177117024),\n",
       " Value (data = 0.30233677715514334)]"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # targets\n",
    "ypred = [n(x) for x in xs] # predictions\n",
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will change the weights of the neural network to make the predictions better\n",
    "\n",
    "### Remember loss is a single number which measures how erroneous was our prediction. Thus this has now become an optimisation problem where we want to minimuze the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{square error loss, }L = (y_{\\text{ground truth}} - y_{\\text{predicted}})^2$ is the (ignoring the sign) the error between our prediction and the ground truth\n",
    "\n",
    "$$\\text{Mean square error loss, MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_{\\text{gt,i}} - y_{\\text{out,i}})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value (data = 0.3391497628305942),\n",
       " Value (data = 0.02242639373173663),\n",
       " Value (data = 2.182979512565679),\n",
       " Value (data = 0.4867339725102722)]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ygt - yout)**2 for ygt, yout in zip(ys, ypred)] # squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value (data = 0.7578224104095705)\n"
     ]
    }
   ],
   "source": [
    "loss = sum ([(ygt - yout)**2 for ygt, yout in zip(ys, ypred)])/len(ys) # total loss, mean squared error\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46587069655085633"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because this gradient has a negative value, the influence of this particular weight of this particular neuron is also negative. I.e slightly increasing the weight of this neuron will make the loss go down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_dot(loss) # uncomment to see the diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important thing to note here is the input layer gradients are not useful to us. The inputs to the network are given. They are not changing. We are only interested in changing the gradients of the weigts and biases of the network\n",
    "\n",
    "### Now we want some method to gather up all the parameters of the network that we want to nudge thus we modify the classes once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "  def __init__ (self, nin): \n",
    "    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)] \n",
    "    self.b = Value(random.uniform(-1,1))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # w*x + b\n",
    "    act = sum([wi*xi for wi, xi in zip(self.w, x)], self.b)\n",
    "    out = act.tanh()\n",
    "    return out\n",
    "  \n",
    "  def parameters(self): # pytorch also has a similar method to get the parameters\n",
    "    return self.w + [self.b] # weights itself is a list of Value objects, so we can concatenate them with a listified bias\n",
    "  \n",
    "\n",
    "class Layer:\n",
    "\n",
    "  def __init__(self, nin, nout):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nout)] # number of neurons in the layer\n",
    "\n",
    "  def __call__(self, x):\n",
    "    outs = [n(x) for n in self.neurons]\n",
    "    return outs[0] if len(outs) == 1 else outs\n",
    "  \n",
    "  def parameters(self):\n",
    "\n",
    "    return [p for n in self.neurons for p in n.parameters()] # flattening the list of parameters from all neurons in the layer\n",
    "    # Does the same as the following commented code\n",
    "    # params = []\n",
    "    # for neuron in self.neurons:\n",
    "    #   ps = neuron.parameters()\n",
    "    #   params.extend(ps)\n",
    "    # return params\n",
    "\n",
    "class MLP:\n",
    "  def __init__(self, nin, nouts): # list of number of neurons in each layer\n",
    "    sz = [nin] + nouts\n",
    "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(sz)-1)] # creating the layers\n",
    "\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "\n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinitialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value (data = -0.9485006099466228),\n",
       " Value (data = -0.8123337543222134),\n",
       " Value (data = -0.9864917475756863),\n",
       " Value (data = -0.3004470981945961)]"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = MLP(3, [4, 4, 1]) # 3 inputs, two hidden layers with 4 neurons each, 1 output\n",
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # targets\n",
    "ypred = [n(x) for x in xs] # predictions\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value (data = 0.4330200364639387),\n",
       " Value (data = -0.466132136019062),\n",
       " Value (data = 0.8953608600217835),\n",
       " Value (data = -0.9711660178268937),\n",
       " Value (data = 0.8184352382762274),\n",
       " Value (data = 0.43225215339177003),\n",
       " Value (data = -0.545216888918822),\n",
       " Value (data = 0.4259463587508736),\n",
       " Value (data = 0.9826778966893843),\n",
       " Value (data = -0.682985747957535),\n",
       " Value (data = -0.40793041324361834),\n",
       " Value (data = -0.15298115106453447),\n",
       " Value (data = -0.1934800000499559),\n",
       " Value (data = -0.723656900372736),\n",
       " Value (data = -0.9181094535133341),\n",
       " Value (data = 0.5530171989199488),\n",
       " Value (data = -0.1746434053795034),\n",
       " Value (data = -0.246030388828121),\n",
       " Value (data = -0.8190481697780183),\n",
       " Value (data = 0.19062057359985363),\n",
       " Value (data = 0.1449190342473674),\n",
       " Value (data = 0.8889873827209906),\n",
       " Value (data = 0.8233622841523025),\n",
       " Value (data = -0.9007436193409335),\n",
       " Value (data = -0.7875982123604954),\n",
       " Value (data = 0.08398595138635234),\n",
       " Value (data = -0.0712979547593302),\n",
       " Value (data = 0.05874013559726454),\n",
       " Value (data = 0.2575344866903433),\n",
       " Value (data = -0.9555111727876431),\n",
       " Value (data = 0.5348143702000516),\n",
       " Value (data = -0.3517936167498239),\n",
       " Value (data = 0.17564104919148948),\n",
       " Value (data = -0.004439260518667165),\n",
       " Value (data = -0.4227681740818492),\n",
       " Value (data = 0.623890678470961),\n",
       " Value (data = -0.5401496787907261),\n",
       " Value (data = -0.9254261543814459),\n",
       " Value (data = -0.6369229304809021),\n",
       " Value (data = -0.3315696718318386),\n",
       " Value (data = -0.6297504405271439)]"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value (data = 1.380804593703865)\n"
     ]
    }
   ],
   "source": [
    "loss = sum ([(ygt - yout)**2 for ygt, yout in zip(ys, ypred)])/len(ys) # total loss, mean squared error\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's slightly change the parameters according to the gradient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4330200364639387"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nudging the parameters in the negative gradient direction\n",
    "for p in n.parameters():\n",
    "  p.data += -0.01 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43297145826957273"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us recalculate the loss and see the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old loss: 1.380804593703865\n",
      "New loss: 1.3419742819043305\n"
     ]
    }
   ],
   "source": [
    "print(f\"Old loss: {loss.data}\")\n",
    "ypred = [n(x) for x in xs]\n",
    "loss = sum ([(ygt - yout)**2 for ygt, yout in zip(ys, ypred)])/len(ys) # total loss, mean squared error\n",
    "print(f\"New loss: {loss.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool. We can see that we have to do few things in order to reduce the loss\n",
    "1. Forward pass\n",
    "2. Backward pass\n",
    "3. Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "loss_history = []\n",
    "for k in range (100):\n",
    "  # forward pass\n",
    "  ypred = [n(x) for x in xs]\n",
    "  # calculate the loss\n",
    "  loss = sum ([(ygt - yout)**2 for ygt, yout in zip(ys, ypred)])/len(ys) # total loss, mean squared error\n",
    "  # backward pass\n",
    "  # reset the gradients\n",
    "  for p in n.parameters():\n",
    "    p.grad = 0.0\n",
    "  loss.backward()\n",
    "  # update the parameters\n",
    "  for p in n.parameters():\n",
    "    p.data += -0.1 * p.grad\n",
    "  # store the loss for plotting\n",
    "  loss_history.append((k+1, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([x for x, _ in loss_history], [y for _, y in loss_history])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value:1.0 \t Predicted Value:Value (data = 0.9389416640059781)\n",
      "Actual value:-1.0 \t Predicted Value:Value (data = -0.9274730349302557)\n",
      "Actual value:-1.0 \t Predicted Value:Value (data = -0.9719050781838812)\n",
      "Actual value:1.0 \t Predicted Value:Value (data = 0.9471260257953438)\n"
     ]
    }
   ],
   "source": [
    "for ygt,yout in zip(ys, ypred):\n",
    "  print(f\"Actual value:{ygt} \\t Predicted Value:{yout}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
